{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Experiments comparing the performance of traditional pooling operations and entropy pooling within a shallow neural network and Lenet. The experiments use MNIST and FashionMNIST."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "transform = transforms.Compose(\n",
    "    [transforms.ToTensor(),\n",
    "     transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))])\n",
    "\n",
    "trainset = torchvision.datasets.MNIST(root='./data', train=True,\n",
    "                                        download=True, transform=transform)\n",
    "# trainset = torchvision.datasets.FashionMNIST(root='./data', train=True,\n",
    "#                                         download=True, transform=transform)\n",
    "\n",
    "trainloader = torch.utils.data.DataLoader(trainset, batch_size=4,\n",
    "                                          shuffle=True, num_workers=8)\n",
    "\n",
    "testset = torchvision.datasets.MNIST(root='./data', train=False,\n",
    "                                       download=True, transform=transform)\n",
    "# testset = torchvision.datasets.FashionMNIST(root='./data', train=False,\n",
    "#                                        download=True, transform=transform)\n",
    "\n",
    "testloader = torch.utils.data.DataLoader(testset, batch_size=4,\n",
    "                                         shuffle=False, num_workers=8)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.nn.modules.utils import _pair, _quadruple\n",
    "import time\n",
    "from skimage.measure import shannon_entropy\n",
    "from scipy import stats\n",
    "\n",
    "from torch.nn.modules.utils import _pair, _quadruple\n",
    "import time\n",
    "from skimage.measure import shannon_entropy\n",
    "from scipy import stats\n",
    "import numpy as np\n",
    "\n",
    "class EntropyPool2d(nn.Module):\n",
    "\n",
    "    def __init__(self, kernel_size=3, stride=1, padding=0, same=False, entr='high'):\n",
    "        super(EntropyPool2d, self).__init__()\n",
    "        self.k = _pair(kernel_size)\n",
    "        self.stride = _pair(stride)\n",
    "        self.padding = _quadruple(padding)  # convert to l, r, t, b\n",
    "        self.same = same\n",
    "        self.entr = entr\n",
    "\n",
    "    def _padding(self, x):\n",
    "        if self.same:\n",
    "            ih, iw = x.size()[2:]\n",
    "            if ih % self.stride[0] == 0:\n",
    "                ph = max(self.k[0] - self.stride[0], 0)\n",
    "            else:\n",
    "                ph = max(self.k[0] - (ih % self.stride[0]), 0)\n",
    "            if iw % self.stride[1] == 0:\n",
    "                pw = max(self.k[1] - self.stride[1], 0)\n",
    "            else:\n",
    "                pw = max(self.k[1] - (iw % self.stride[1]), 0)\n",
    "            pl = pw // 2\n",
    "            pr = pw - pl\n",
    "            pt = ph // 2\n",
    "            pb = ph - pt\n",
    "            padding = (pl, pr, pt, pb)\n",
    "        else:\n",
    "            padding = self.padding\n",
    "        return padding\n",
    "    \n",
    "    def forward(self, x):\n",
    "        # using existing pytorch functions and tensor ops so that we get autograd, \n",
    "        # would likely be more efficient to implement from scratch at C/Cuda level\n",
    "        start = time.time()\n",
    "        x = F.pad(x, self._padding(x), mode='reflect')\n",
    "        x_detached = x.cpu().detach()\n",
    "        x_unique, x_indices, x_inverse, x_counts = np.unique(x_detached,\n",
    "                                                             return_index=True, \n",
    "                                                             return_inverse=True, \n",
    "                                                             return_counts=True)        \n",
    "        freq = torch.FloatTensor([x_counts[i] / len(x_inverse) for i in x_inverse]).cuda()\n",
    "        x_probs = freq.view(x.shape)       \n",
    "        x_probs = x_probs.unfold(2, self.k[0], self.stride[0]).unfold(3, self.k[1], self.stride[1])\n",
    "        x_probs = x_probs.contiguous().view(x_probs.size()[:4] + (-1,))\n",
    "        if self.entr is 'high':\n",
    "            x_probs, indices = torch.min(x_probs.cuda(), dim=-1)\n",
    "        elif self.entr is 'low':\n",
    "            x_probs, indices = torch.max(x_probs.cuda(), dim=-1)\n",
    "        else:\n",
    "            raise Exception('Unknown entropy mode: {}'.format(self.entr))\n",
    "            \n",
    "        x = x.unfold(2, self.k[0], self.stride[0]).unfold(3, self.k[1], self.stride[1])\n",
    "        x = x.contiguous().view(x.size()[:4] + (-1,))\n",
    "        indices = indices.view(indices.size() + (-1,))\n",
    "        pool = torch.gather(input=x, dim=-1, index=indices)\n",
    "        \n",
    "        return pool.squeeze(-1)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "import time\n",
    "from sklearn.metrics import f1_score\n",
    "\n",
    "MAX = 'max'\n",
    "AVG = 'avg'\n",
    "HIGH_ENTROPY = 'high_entr'\n",
    "LOW_ENTROPY = 'low_entr'\n",
    "\n",
    "class Net1Pool(nn.Module):\n",
    "    def __init__(self, num_classes=10, pooling=MAX):\n",
    "        super(Net1Pool, self).__init__()\n",
    "        self.conv1 = nn.Conv2d(1, 30, 5)\n",
    "        \n",
    "        if pooling is MAX:\n",
    "            self.pool = nn.MaxPool2d(2, 2)\n",
    "        elif pooling is AVG:\n",
    "            self.pool = nn.AvgPool2d(2, 2)\n",
    "        elif pooling is HIGH_ENTROPY:\n",
    "            self.pool = EntropyPool2d(2, 2, entr='high')\n",
    "        elif pooling is LOW_ENTROPY:\n",
    "            self.pool = EntropyPool2d(2, 2, entr='low')\n",
    "              \n",
    "        self.fc0 = nn.Linear(30 * 12 * 12, num_classes)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.pool(F.relu(self.conv1(x)))\n",
    "        x = x.view(-1, 30 * 12 * 12)\n",
    "        x = F.relu(self.fc0(x))\n",
    "        return x\n",
    "\n",
    "\n",
    "class Net2Pool(nn.Module):\n",
    "    def __init__(self, num_classes=10, pooling=MAX):\n",
    "        super(Net2Pool, self).__init__()\n",
    "        self.conv1 = nn.Conv2d(1, 50, 5, 1)\n",
    "        self.conv2 = nn.Conv2d(50, 50, 5, 1)\n",
    "        \n",
    "        if pooling is MAX:\n",
    "            self.pool = nn.MaxPool2d(2, 2)\n",
    "        elif pooling is AVG:\n",
    "            self.pool = nn.AvgPool2d(2, 2)\n",
    "        elif pooling is HIGH_ENTROPY:\n",
    "            self.pool = EntropyPool2d(2, 2, entr='high')\n",
    "        elif pooling is LOW_ENTROPY:\n",
    "            self.pool = EntropyPool2d(2, 2, entr='low')\n",
    "              \n",
    "        self.fc1 = nn.Linear(4*4*50, 500)\n",
    "        self.fc2 = nn.Linear(500, num_classes)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = F.relu(self.conv1(x))\n",
    "        x = self.pool(x)\n",
    "        x = F.relu(self.conv2(x))\n",
    "        x = self.pool(x)\n",
    "\n",
    "        x = x.view(-1, 4*4*50)\n",
    "        x = F.relu(self.fc1(x))\n",
    "        x = self.fc2(x)\n",
    "        return x\n",
    "\n",
    "def configure_net(net, device):\n",
    "    net.to(device)\n",
    "    criterion = nn.CrossEntropyLoss()\n",
    "    optimizer = optim.SGD(net.parameters(), lr=0.001, momentum=0.9)\n",
    "    return net, optimizer, criterion\n",
    "\n",
    "def train(net, optimizer, criterion, trainloader, device, epochs=10, logging=2000):\n",
    "    for epoch in range(epochs):  \n",
    "        running_loss = 0.0\n",
    "        for i, data in enumerate(trainloader, 0):\n",
    "            start = time.time()\n",
    "            inputs, labels = data\n",
    "            inputs, labels = inputs.to(device), labels.to(device)\n",
    "        \n",
    "            optimizer.zero_grad()\n",
    "            outputs = net(inputs)\n",
    "            loss = criterion(outputs, labels)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "            running_loss += loss.item()\n",
    "            if i % logging == logging - 1:    \n",
    "                print('[%d, %5d] loss: %.3f duration: %.5f' %\n",
    "                      (epoch + 1, i + 1, running_loss / logging, time.time() - start))\n",
    "                running_loss = 0.0\n",
    "\n",
    "    print('Finished Training')\n",
    "    \n",
    "def test(net, testloader, device):\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    predictions = []\n",
    "    l = []\n",
    "    with torch.no_grad():\n",
    "        for data in testloader:\n",
    "            images, labels = data\n",
    "            images, labels = images.to(device), labels.to(device)\n",
    "\n",
    "            outputs = net(images)\n",
    "            _, predicted = torch.max(outputs.data, 1)\n",
    "            total += labels.size(0)\n",
    "            correct += (predicted == labels).sum().item()\n",
    "            predictions.extend(predicted.cpu().numpy())\n",
    "            l.extend(labels.cpu().numpy())\n",
    "\n",
    "    print('Accuracy: {}'.format(100 * correct / total))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "epochs = 10\n",
    "logging = 15000\n",
    "num_classes = 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('- - - - - - -  - -- - - - 2 pool - -  - - - - - - - - - - - - - -')\n",
    "print('- - - - - - -  - -- - - - MAX - -  - - - - - - - - - - - - - -')\n",
    "\n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "net, optimizer, criterion = configure_net(Net2Pool(num_classes=num_classes, pooling=MAX), device)\n",
    "train(net, optimizer, criterion, trainloader, device, epochs=epochs, logging=logging)\n",
    "test(net, testloader, device)\n",
    "\n",
    "print('- - - - - - -  - -- - - - AVG - -  - - - - - - - - - - - - - -')\n",
    "\n",
    "net, optimizer, criterion = configure_net(Net2Pool(num_classes=num_classes, pooling=AVG), device)\n",
    "train(net, optimizer, criterion, trainloader, device, epochs=epochs, logging=logging)\n",
    "test(net, testloader, device)\n",
    "\n",
    "print('- - - - - - -  - -- - - - HIGH - -  - - - - - - - - - - - - - -')\n",
    "\n",
    "net, optimizer, criterion = configure_net(Net2Pool(num_classes=num_classes, pooling=HIGH_ENTROPY), device)\n",
    "train(net, optimizer, criterion, trainloader, device, epochs=epochs, logging=logging)\n",
    "test(net, testloader, device)\n",
    "\n",
    "print('- - - - - - -  - -- - - - LOW - -  - - - - - - - - - - - - - -')\n",
    "\n",
    "net, optimizer, criterion = configure_net(Net2Pool(num_classes=num_classes, pooling=LOW_ENTROPY), device)\n",
    "train(net, optimizer, criterion, trainloader, device, epochs=epochs, logging=logging)\n",
    "test(net, testloader, device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('- - - - - - -  - -- - - -1 pool - -  - - - - - - - - - - - - - -')\n",
    "print('- - - - - - -  - -- - - - MAX - -  - - - - - - - - - - - - - -')\n",
    "\n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "net, optimizer, criterion = configure_net(Net1Pool(num_classes=num_classes, pooling=MAX), device)\n",
    "train(net, optimizer, criterion, trainloader, device, epochs=epochs, logging=logging)\n",
    "test(net, testloader, device)\n",
    "\n",
    "print('- - - - - - -  - -- - - - AVG - -  - - - - - - - - - - - - - -')\n",
    "\n",
    "net, optimizer, criterion = configure_net(Net1Pool(num_classes=num_classes, pooling=AVG), device)\n",
    "train(net, optimizer, criterion, trainloader, device, epochs=epochs, logging=logging)\n",
    "test(net, testloader, device)\n",
    "\n",
    "print('- - - - - - -  - -- - - - HIGH - -  - - - - - - - - - - - - - -')\n",
    "\n",
    "net, optimizer, criterion = configure_net(Net1Pool(num_classes=num_classes, pooling=MAX_ENTROPY), device)\n",
    "train(net, optimizer, criterion, trainloader, device, epochs=epochs, logging=logging)\n",
    "test(net, testloader, device)\n",
    "\n",
    "print('- - - - - - -  - -- - - - LOW - -  - - - - - - - - - - - - - -')\n",
    "\n",
    "net, optimizer, criterion = configure_net(Net1Pool(num_classes=num_classes, pooling=MIN_ENTROPY), device)\n",
    "train(net, optimizer, criterion, trainloader, device, epochs=epochs, logging=logging)\n",
    "test(net, testloader, device)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
